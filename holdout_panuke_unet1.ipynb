{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OX1HsM-Ail-k"
   },
   "outputs": [],
   "source": [
    "from skimage.color import rgb2hed, hed2rgb, rgb2hsv, rgb2lab, gray2rgb, hsv2rgb, rgb2gray\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "# import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from random import choice  # Import the choice function from the random module\n",
    "from itertools import chain\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler\n",
    "\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage.morphology import disk\n",
    "from skimage.filters import median\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.activations import *\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Concatenate\n",
    "from tensorflow.keras.initializers import Constant\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import *\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.layers import Input, Conv2D, Activation, Add, Lambda, Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.backend import *\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.color import rgb2hed, hed2rgb, rgb2hsv, rgb2lab, gray2rgb, hsv2rgb, rgb2gray\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.backend import *\n",
    "\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "\n",
    "def f1_score1(y_true,y_pred):\n",
    "    smooth=1\n",
    "    y_true_f = flatten(y_true)\n",
    "    y_pred_f = flatten(y_pred)\n",
    "    intersection = sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (sum(y_true_f) + sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth=1\n",
    "    y_true_f = flatten(y_true)\n",
    "    y_pred_f = flatten(y_pred)\n",
    "    y_true_f = cast(y_true_f, dtype='float32')\n",
    "    y_pred_f = cast(y_pred_f, dtype='float32')\n",
    "    intersection = sum(y_true_f * y_pred_f)\n",
    "    return 1-(2. * intersection + smooth) / (sum(y_true_f) + sum(y_pred_f) + smooth)\n",
    "\n",
    "def jaccard_loss(y_true, y_pred, smooth=100):\n",
    "        intersection = sum(abs(y_true * y_pred), axis=-1)\n",
    "        sum_ = sum(abs(y_true) + abs(y_pred), axis=-1)\n",
    "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "        return (1 - jac) * smooth\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    def dice_coef_loss(y_true, y_pred):\n",
    "        return dice_loss(y_true, y_pred)\n",
    "\n",
    "    def jaccard_distance_loss(y_true, y_pred, smooth=100):\n",
    "        intersection = sum(abs(y_true * y_pred), axis=-1)\n",
    "        sum_ = sum(abs(y_true) + abs(y_pred), axis=-1)\n",
    "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "        return (1 - jac) * smooth\n",
    "\n",
    "    return (jaccard_distance_loss(y_true, y_pred) * dice_coef_loss(y_true, y_pred))/(jaccard_distance_loss(y_true, y_pred) + dice_coef_loss(y_true, y_pred))\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def bce_dice_jaccard_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) + jaccard_loss(y_true, y_pred)\n",
    "\n",
    "def dice_jaccard_loss(y_true, y_pred):\n",
    "    return dice_loss(y_true, y_pred) + jaccard_loss(y_true, y_pred)\n",
    "\n",
    "def jaccard(y_true, y_pred, smooth=100):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    sum_ = tf.reduce_sum(y_true + y_pred)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return jac * smooth\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    im1 = np.asarray(y_true).astype(np.bool)\n",
    "    im2 = np.asarray(y_pred).astype(np.bool)\n",
    "    if im1.shape != im2.shape:\n",
    "        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n",
    "    intersection = np.logical_and(im1, im2)\n",
    "    return 2. * intersection.sum() / (im1.sum() + im2.sum())\n",
    "\n",
    "\n",
    "def IOU_Loss(y_true, y_pred):\n",
    "    answ = tf.keras.metrics.MeanIoU(2, name=None, dtype=None)\n",
    "    answ.update_state(y_true, y_pred)\n",
    "    return answ.result().numpy()\n",
    "\n",
    "\n",
    "def Precision(y_true, y_pred):\n",
    "    answ = tf.keras.metrics.Precision()\n",
    "    answ.update_state(y_true, y_pred)\n",
    "    return answ.result().numpy()\n",
    "\n",
    "\n",
    "def Recall(y_true, y_pred):\n",
    "    answ = tf.keras.metrics.Recall()\n",
    "    answ.update_state(y_true, y_pred)\n",
    "    return answ.result().numpy()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def jaccard_index(seg_mask, gt_mask):\n",
    "    intersection = np.sum(np.logical_and(seg_mask, gt_mask))\n",
    "    union = np.sum(np.logical_or(seg_mask, gt_mask))\n",
    "    jaccard = intersection / union if union > 0 else 0.0\n",
    "    return jaccard\n",
    "\n",
    "def aggregated_jaccard_index(seg_masks, gt_masks):\n",
    "    num_objects = len(seg_masks)\n",
    "    ajis = []\n",
    "\n",
    "    for i in range(num_objects):\n",
    "        jis = [iou(seg_masks[i], gt_mask) for gt_mask in gt_masks]\n",
    "        ajis.append(max(jis))\n",
    "\n",
    "    aji = np.mean(ajis)\n",
    "    return aji\n",
    "\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred)\n",
    "    dice = (2.0 * intersection) / (union + 1e-8)  # Adding a small epsilon to avoid division by zero\n",
    "    return dice * 100  # Convert to percentage\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(np.maximum(y_true, y_pred))\n",
    "    iou = (intersection + 1e-8) / (union + 1e-8)  # Adding a small epsilon to avoid division by zero\n",
    "    return iou * 100  # Convert to percentage\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positive = np.sum(y_true * y_pred)\n",
    "    false_positive = np.sum(np.clip(y_pred - y_true, 0, 1))  # Calculating false positives\n",
    "    precision = (true_positive + 1e-8) / (true_positive + false_positive + 1e-8)  # Adding a small epsilon to avoid division by zero\n",
    "    return precision * 100  # Convert to percentage\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positive = np.sum(y_true * y_pred)\n",
    "    false_negative = np.sum(np.clip(y_true - y_pred, 0, 1))  # Calculating false negatives\n",
    "    recall = (true_positive + 1e-8) / (true_positive + false_negative + 1e-8)  # Adding a small epsilon to avoid division by zero\n",
    "    return recall * 100  # Convert to percentage\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    true_negative = np.sum(np.clip((1 - y_true) * (1 - y_pred), 0, 1))\n",
    "    false_positive = np.sum(np.clip(y_pred - y_true, 0, 1))  # Calculating false positives\n",
    "    specificity = (true_negative + 1e-8) / (true_negative + false_positive + 1e-8)  # Adding a small epsilon to avoid division by zero\n",
    "    return specificity * 100  # Convert to percentage\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    correct_pixels = np.sum(y_true == y_pred)\n",
    "    total_pixels = y_true.size\n",
    "    accuracy = (correct_pixels / total_pixels) * 100\n",
    "    return accuracy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.backend import *\n",
    "\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "  ##### Metrices & Loss #####\n",
    "#------------- Metrice-------------\n",
    "def f1_score1(y_true,y_pred):\n",
    "    smooth=1\n",
    "    y_true_f = flatten(y_true)\n",
    "    y_pred_f = flatten(y_pred)\n",
    "    intersection = sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (sum(y_true_f) + sum(y_pred_f) + smooth)\n",
    "#----------------------------------\n",
    "# -------------Loss----------------\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth=1\n",
    "    y_true_f = flatten(y_true)\n",
    "    y_pred_f = flatten(y_pred)\n",
    "    y_true_f = cast(y_true_f, dtype='float32')\n",
    "    y_pred_f = cast(y_pred_f, dtype='float32')\n",
    "    intersection = sum(y_true_f * y_pred_f)\n",
    "    return 1-(2. * intersection + smooth) / (sum(y_true_f) + sum(y_pred_f) + smooth)\n",
    "\n",
    "def jaccard_loss(y_true, y_pred, smooth=100):\n",
    "        intersection = sum(abs(y_true * y_pred), axis=-1)\n",
    "        sum_ = sum(abs(y_true) + abs(y_pred), axis=-1)\n",
    "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "        return (1 - jac) * smooth\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    def dice_coef_loss(y_true, y_pred):\n",
    "        return dice_loss(y_true, y_pred)\n",
    "\n",
    "    def jaccard_distance_loss(y_true, y_pred, smooth=100):\n",
    "        intersection = sum(abs(y_true * y_pred), axis=-1)\n",
    "        sum_ = sum(abs(y_true) + abs(y_pred), axis=-1)\n",
    "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "        return (1 - jac) * smooth\n",
    "\n",
    "    return (jaccard_distance_loss(y_true, y_pred) * dice_coef_loss(y_true, y_pred))/(jaccard_distance_loss(y_true, y_pred) + dice_coef_loss(y_true, y_pred))\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def bce_dice_jaccard_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred) + jaccard_loss(y_true, y_pred)\n",
    "\n",
    "def dice_jaccard_loss(y_true, y_pred):\n",
    "    return dice_loss(y_true, y_pred) + jaccard_loss(y_true, y_pred)\n",
    "#-----------------------------------\n",
    "def calculate_fpr(false_positives, true_negatives):\n",
    "    \"\"\"\n",
    "    Calculate the false positive rate (FPR) given the number of false positives (FP)\n",
    "    and the number of true negatives (TN).\n",
    "\n",
    "    Args:\n",
    "    false_positives (int): Number of false positive cases.\n",
    "    true_negatives (int): Number of true negative cases.\n",
    "\n",
    "    Returns:\n",
    "    float: False positive rate (FPR).\n",
    "    \"\"\"\n",
    "    total_negative = false_positives + true_negatives\n",
    "    if total_negative == 0:\n",
    "        return 0  # Handling division by zero\n",
    "    fpr = false_positives / total_negative\n",
    "    return fpr\n",
    "\n",
    "def calculate_fnr(false_negatives, true_positives):\n",
    "    \"\"\"\n",
    "    Calculate the false negative rate (FNR) given the number of false negatives (FN)\n",
    "    and the number of true positives (TP).\n",
    "\n",
    "    Args:\n",
    "    false_negatives (int): Number of false negative cases.\n",
    "    true_positives (int): Number of true positive cases.\n",
    "\n",
    "    Returns:\n",
    "    float: False negative rate (FNR).\n",
    "    \"\"\"\n",
    "    total_positive = false_negatives + true_positives\n",
    "    if total_positive == 0:\n",
    "        return 0  # Handling division by zero\n",
    "    fnr = false_negatives / total_positive\n",
    "    return fnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total image files found: 6103\n",
      "Total mask files found: 6103\n",
      "Loaded 6103 images and 6103 masks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_images_and_masks(data_path):\n",
    "    images = []\n",
    "    masks = []\n",
    "    \n",
    "    image_files = []\n",
    "    mask_files = []\n",
    "\n",
    "    # Gather all image and mask files\n",
    "    for root, dirs, files in os.walk(data_path):\n",
    "        if 'images' in root:\n",
    "            image_files.extend([os.path.join(root, f) for f in files if f.endswith('.png')])\n",
    "        if 'sem_masks' in root:\n",
    "            mask_files.extend([os.path.join(root, f) for f in files if f.endswith('.png')])\n",
    "    \n",
    "    print(f\"Total image files found: {len(image_files)}\")\n",
    "    print(f\"Total mask files found: {len(mask_files)}\")\n",
    "\n",
    "    # Sort the files to ensure the order matches\n",
    "    image_files.sort()\n",
    "    mask_files.sort()\n",
    "    \n",
    "    # Ensure the number of images matches the number of masks\n",
    "    if len(image_files) != len(mask_files):\n",
    "        print(\"Number of images and masks do not match!\")\n",
    "        return np.array(images), np.array(masks)\n",
    "    \n",
    "    # Load and process the images and masks\n",
    "    for img_file, mask_file in zip(image_files, mask_files):\n",
    "        try:\n",
    "            # Read the images\n",
    "            image = cv2.imread(img_file)\n",
    "            mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            if image is None:\n",
    "                print(f\"Failed to load image: {img_file}\")\n",
    "                continue\n",
    "            if mask is None:\n",
    "                print(f\"Failed to load mask: {mask_file}\")\n",
    "                continue\n",
    "            \n",
    "            # Normalize images and masks\n",
    "            image = image.astype(np.float32) / 255.0\n",
    "            mask = mask.astype(np.float32) / 255.0\n",
    "            \n",
    "            # Threshold masks\n",
    "            mask[mask > 0.0] = 1.0\n",
    "            \n",
    "            images.append(image)\n",
    "            masks.append(mask)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing files {img_file} and {mask_file}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Update the path to your dataset directory\n",
    "data_path = 'C:/Users/HP/OneDrive/Desktop/Rashika/Paper_1/dataset_pannuke2/'\n",
    "train_images_hc, train_masks_hc = load_images_and_masks(data_path)\n",
    "\n",
    "print(f\"Loaded {len(train_images_hc)} images and {len(train_masks_hc)} masks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_images_hc, train_masks_hc,\n",
    "                                        test_size=0.2, random_state=15)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid,\n",
    "                                        test_size=0.2, random_state=15)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(train_images_hc, train_masks_hc,\n",
    "#                                         test_size=0.2, random_state=5)\n",
    "# X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid,\n",
    "#                                         test_size=0.2, random_state=5)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(train_images_hc, train_masks_hc,\n",
    "#                                         test_size=0.2, random_state=10)\n",
    "# X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid,\n",
    "#                                         test_size=0.2, random_state=10)\n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(train_images_hc, train_masks_hc,\n",
    "#                                         test_size=0.2, random_state=15)\n",
    "# X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid,\n",
    "#                                         test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 8)  224         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 8)  32         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 8)  584         ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 8)  32         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 8)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 16  1168        ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 16  64         ['conv2d_2[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 16  2320        ['batch_normalization_2[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 16  64         ['conv2d_3[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 16)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 32)   4640        ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 32)   9248        ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 32)  128         ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 32)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 64)   18496       ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 64)   36928       ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 64)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 128)  73856       ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 128)  147584      ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 32, 32, 128)  0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 192)  0           ['up_sampling2d[0][0]',          \n",
      "                                                                  'batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 64)   110656      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 32, 32, 64)  256         ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 64)   36928       ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 32, 64)  256         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 64)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 96)   0           ['up_sampling2d_1[0][0]',        \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 64, 32)   27680       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 64, 64, 32)  128         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 32)   9248        ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 64, 64, 32)  128         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 32  0          ['batch_normalization_13[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 48  0           ['up_sampling2d_2[0][0]',        \n",
      "                                )                                 'batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 128, 16  6928        ['concatenate_2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 128, 128, 16  64         ['conv2d_14[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 16  2320        ['batch_normalization_14[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 128, 128, 16  64         ['conv2d_15[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 16  0          ['batch_normalization_15[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 24  0           ['up_sampling2d_3[0][0]',        \n",
      "                                )                                 'batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 256, 256, 8)  1736        ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 256, 256, 8)  32         ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 256, 256, 8)  584         ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 256, 256, 8)  32         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 256, 256, 1)  9           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 494,081\n",
      "Trainable params: 492,609\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "611/611 [==============================] - 91s 125ms/step - loss: 0.2807 - accuracy: 0.8992 - val_loss: 0.2179 - val_accuracy: 0.9121\n",
      "Epoch 2/50\n",
      "611/611 [==============================] - 71s 117ms/step - loss: 0.1747 - accuracy: 0.9275 - val_loss: 0.1842 - val_accuracy: 0.9222\n",
      "Epoch 3/50\n",
      "611/611 [==============================] - 72s 119ms/step - loss: 0.1601 - accuracy: 0.9326 - val_loss: 0.1714 - val_accuracy: 0.9281\n",
      "Epoch 4/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.1525 - accuracy: 0.9358 - val_loss: 0.1676 - val_accuracy: 0.9292\n",
      "Epoch 5/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.1464 - accuracy: 0.9384 - val_loss: 0.1615 - val_accuracy: 0.9323\n",
      "Epoch 6/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.1415 - accuracy: 0.9405 - val_loss: 0.1575 - val_accuracy: 0.9340\n",
      "Epoch 7/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.1363 - accuracy: 0.9426 - val_loss: 0.1584 - val_accuracy: 0.9337\n",
      "Epoch 8/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.1323 - accuracy: 0.9444 - val_loss: 0.1589 - val_accuracy: 0.9328\n",
      "Epoch 9/50\n",
      "611/611 [==============================] - 71s 117ms/step - loss: 0.1267 - accuracy: 0.9469 - val_loss: 0.1598 - val_accuracy: 0.9333\n",
      "Epoch 10/50\n",
      "611/611 [==============================] - 69s 113ms/step - loss: 0.1228 - accuracy: 0.9486 - val_loss: 0.1613 - val_accuracy: 0.9332\n",
      "Epoch 11/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.1188 - accuracy: 0.9503 - val_loss: 0.1649 - val_accuracy: 0.9312\n",
      "Epoch 12/50\n",
      "611/611 [==============================] - 72s 117ms/step - loss: 0.1155 - accuracy: 0.9516 - val_loss: 0.1656 - val_accuracy: 0.9313\n",
      "Epoch 13/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.1119 - accuracy: 0.9532 - val_loss: 0.1671 - val_accuracy: 0.9320\n",
      "Epoch 14/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.1083 - accuracy: 0.9547 - val_loss: 0.1715 - val_accuracy: 0.9308\n",
      "Epoch 15/50\n",
      "611/611 [==============================] - 72s 119ms/step - loss: 0.1064 - accuracy: 0.9555 - val_loss: 0.1801 - val_accuracy: 0.9285\n",
      "Epoch 16/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.1040 - accuracy: 0.9565 - val_loss: 0.1923 - val_accuracy: 0.9242\n",
      "Epoch 17/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.1025 - accuracy: 0.9571 - val_loss: 0.1808 - val_accuracy: 0.9287\n",
      "Epoch 18/50\n",
      "611/611 [==============================] - 73s 119ms/step - loss: 0.0991 - accuracy: 0.9585 - val_loss: 0.1852 - val_accuracy: 0.9287\n",
      "Epoch 19/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0962 - accuracy: 0.9598 - val_loss: 0.1883 - val_accuracy: 0.9282\n",
      "Epoch 20/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0950 - accuracy: 0.9603 - val_loss: 0.1844 - val_accuracy: 0.9294\n",
      "Epoch 21/50\n",
      "611/611 [==============================] - 73s 119ms/step - loss: 0.0927 - accuracy: 0.9612 - val_loss: 0.1853 - val_accuracy: 0.9303\n",
      "Epoch 22/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0901 - accuracy: 0.9623 - val_loss: 0.1905 - val_accuracy: 0.9302\n",
      "Epoch 23/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0895 - accuracy: 0.9625 - val_loss: 0.1966 - val_accuracy: 0.9281\n",
      "Epoch 24/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0882 - accuracy: 0.9630 - val_loss: 0.1977 - val_accuracy: 0.9288\n",
      "Epoch 25/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0869 - accuracy: 0.9636 - val_loss: 0.1978 - val_accuracy: 0.9297\n",
      "Epoch 26/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0862 - accuracy: 0.9639 - val_loss: 0.1951 - val_accuracy: 0.9318\n",
      "Epoch 27/50\n",
      "611/611 [==============================] - 72s 117ms/step - loss: 0.0852 - accuracy: 0.9643 - val_loss: 0.1935 - val_accuracy: 0.9311\n",
      "Epoch 28/50\n",
      "611/611 [==============================] - 72s 117ms/step - loss: 0.0841 - accuracy: 0.9647 - val_loss: 0.1944 - val_accuracy: 0.9314\n",
      "Epoch 29/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0827 - accuracy: 0.9653 - val_loss: 0.2002 - val_accuracy: 0.9310\n",
      "Epoch 30/50\n",
      "611/611 [==============================] - 71s 117ms/step - loss: 0.0818 - accuracy: 0.9657 - val_loss: 0.1946 - val_accuracy: 0.9331\n",
      "Epoch 31/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0805 - accuracy: 0.9662 - val_loss: 0.1999 - val_accuracy: 0.9314\n",
      "Epoch 32/50\n",
      "611/611 [==============================] - 71s 117ms/step - loss: 0.0799 - accuracy: 0.9665 - val_loss: 0.2091 - val_accuracy: 0.9304\n",
      "Epoch 33/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0794 - accuracy: 0.9667 - val_loss: 0.2155 - val_accuracy: 0.9283\n",
      "Epoch 34/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0782 - accuracy: 0.9671 - val_loss: 0.2248 - val_accuracy: 0.9255\n",
      "Epoch 35/50\n",
      "611/611 [==============================] - 73s 119ms/step - loss: 0.0772 - accuracy: 0.9676 - val_loss: 0.2196 - val_accuracy: 0.9296\n",
      "Epoch 36/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0769 - accuracy: 0.9677 - val_loss: 0.2111 - val_accuracy: 0.9300\n",
      "Epoch 37/50\n",
      "611/611 [==============================] - 70s 114ms/step - loss: 0.0771 - accuracy: 0.9676 - val_loss: 0.2107 - val_accuracy: 0.9311\n",
      "Epoch 38/50\n",
      "611/611 [==============================] - 71s 115ms/step - loss: 0.0756 - accuracy: 0.9682 - val_loss: 0.2074 - val_accuracy: 0.9316\n",
      "Epoch 39/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0748 - accuracy: 0.9686 - val_loss: 0.2135 - val_accuracy: 0.9309\n",
      "Epoch 40/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0741 - accuracy: 0.9688 - val_loss: 0.2178 - val_accuracy: 0.9290\n",
      "Epoch 41/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0740 - accuracy: 0.9689 - val_loss: 0.2106 - val_accuracy: 0.9310\n",
      "Epoch 42/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0743 - accuracy: 0.9687 - val_loss: 0.2152 - val_accuracy: 0.9293\n",
      "Epoch 43/50\n",
      "611/611 [==============================] - 72s 119ms/step - loss: 0.0734 - accuracy: 0.9691 - val_loss: 0.2138 - val_accuracy: 0.9304\n",
      "Epoch 44/50\n",
      "611/611 [==============================] - 72s 117ms/step - loss: 0.0722 - accuracy: 0.9696 - val_loss: 0.2218 - val_accuracy: 0.9293\n",
      "Epoch 45/50\n",
      "611/611 [==============================] - 72s 117ms/step - loss: 0.0715 - accuracy: 0.9699 - val_loss: 0.2158 - val_accuracy: 0.9295\n",
      "Epoch 46/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0713 - accuracy: 0.9700 - val_loss: 0.2258 - val_accuracy: 0.9290\n",
      "Epoch 47/50\n",
      "611/611 [==============================] - 72s 119ms/step - loss: 0.0702 - accuracy: 0.9705 - val_loss: 0.2280 - val_accuracy: 0.9288\n",
      "Epoch 48/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0697 - accuracy: 0.9706 - val_loss: 0.2318 - val_accuracy: 0.9268\n",
      "Epoch 49/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0697 - accuracy: 0.9706 - val_loss: 0.2399 - val_accuracy: 0.9263\n",
      "Epoch 50/50\n",
      "611/611 [==============================] - 72s 118ms/step - loss: 0.0697 - accuracy: 0.9706 - val_loss: 0.2362 - val_accuracy: 0.9265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: unet_pannuke5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: unet_pannuke5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 5s 292ms/step\n",
      "Dice Coefficient: 79.94%\n",
      "IoU (Jaccard Index): 66.59%\n",
      "Precision: 69.56%\n",
      "Recall: 93.97%\n",
      "Specificity: 89.82%\n",
      "Accuracy: 90.65%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24734006350>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1\n",
    "    y_true_f = flatten(y_true)\n",
    "    y_pred_f = flatten(y_pred)\n",
    "    y_true_f = cast(y_true_f, dtype='float32')\n",
    "    y_pred_f = cast(y_pred_f, dtype='float32')\n",
    "    intersection = sum(y_true_f * y_pred_f)\n",
    "    return 1 - (2. * intersection + smooth) / (sum(y_true_f) + sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "\n",
    "def bce_loss(y_true, y_pred):\n",
    "    return tf.squeeze(binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred), axis=0)\n",
    "\n",
    "\n",
    "def loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "    def dice_coef_loss(y_true, y_pred):\n",
    "        return dice_loss(y_true, y_pred)\n",
    "\n",
    "    def jaccard_distance_loss(y_true, y_pred, smooth=100):\n",
    "        intersection = sum(abs(y_true * y_pred), axis=-1)\n",
    "        sum_ = sum(abs(y_true) + abs(y_pred), axis=-1)\n",
    "        jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "        return (1 - jac) * smooth\n",
    "\n",
    "    return (jaccard_distance_loss(y_true, y_pred) * dice_coef_loss(y_true, y_pred)) / (\n",
    "                jaccard_distance_loss(y_true, y_pred) + dice_coef_loss(y_true, y_pred))\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.activations import *\n",
    "# from loss import *\n",
    "# from metrics import *\n",
    "\n",
    "\n",
    "def down_block(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = BatchNormalization(epsilon=1e-3, beta_initializer=Constant(0.0), gamma_initializer=Constant(1.0), momentum=0.5)(c)\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    c = BatchNormalization(epsilon=1e-3, beta_initializer=Constant(0.0), gamma_initializer=Constant(1.0), momentum=0.5)(c)\n",
    "    p = MaxPooling2D((2, 2), (2, 2))(c)\n",
    "    return c, p\n",
    "\n",
    "def up_block(x, skip, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    us = UpSampling2D((2, 2))(x)\n",
    "    concat = Concatenate()([us, skip])\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(concat)\n",
    "    c = BatchNormalization(epsilon=1e-3, beta_initializer=Constant(0.0), gamma_initializer=Constant(1.0), momentum=0.5)(c)\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    c = BatchNormalization(epsilon=1e-3, beta_initializer=Constant(0.0), gamma_initializer=Constant(1.0), momentum=0.5)(c)\n",
    "    return c\n",
    "\n",
    "def bottleneck(x, filters, kernel_size=(3, 3), padding=\"same\", strides=1):\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(x)\n",
    "    c = BatchNormalization(epsilon=1e-3, beta_initializer=Constant(0.0), gamma_initializer=Constant(1.0), momentum=0.5)(c)\n",
    "    c = Conv2D(filters, kernel_size, padding=padding, strides=strides, activation=\"relu\")(c)\n",
    "    c = BatchNormalization(epsilon=1e-3, beta_initializer=Constant(0.0), gamma_initializer=Constant(1.0), momentum=0.5)(c)\n",
    "    return c\n",
    "\n",
    "def UNet():\n",
    "    f = [8, 16, 32, 64, 128, 256, 512]\n",
    "    inputs = Input((256, 256, 3))\n",
    "\n",
    "    p0 = inputs\n",
    "    c1, p1 = down_block(p0, f[0])  # 128 -> 64\n",
    "    c2, p2 = down_block(p1, f[1])  # 64 -> 32\n",
    "    c3, p3 = down_block(p2, f[2])  # 32 -> 16\n",
    "    c4, p4 = down_block(p3, f[3])  # 16 -> 8\n",
    "\n",
    "    bn = bottleneck(p4, f[4])\n",
    "\n",
    "    u1 = up_block(bn, c4, f[3])  # 8 -> 16\n",
    "    u2 = up_block(u1, c3, f[2])  # 16 -> 32\n",
    "    u3 = up_block(u2, c2, f[1])  # 32 -> 64\n",
    "    u4 = up_block(u3, c1, f[0])  # 64 -> 128\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), padding=\"same\", activation=\"sigmoid\")(u4)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "dice_values = []\n",
    "iou_values = []\n",
    "precision_values = []\n",
    "recall_values = []\n",
    "specificity_values = []\n",
    "accuracy_values = []\n",
    "fpr=[]\n",
    "fnr=[]\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "decay_rate = 0.99\n",
    "decay_steps = 10  # Decay the learning rate after every 10 epochs\n",
    "\n",
    "# Define the learning rate schedule\n",
    "def learning_rate_scheduler(epoch):\n",
    "    return initial_learning_rate * decay_rate ** (epoch // decay_steps)\n",
    "\n",
    "# Create an Adam optimizer with the specified initial learning rate\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "\n",
    "# model.compile(optimizer=optimizers.Adam(lr=0.001), loss=dice_loss, metrics=['accuracy'], run_eagerly=True)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(8)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(8)\n",
    "model.summary()\n",
    "\n",
    "model = UNet()\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Use the Dataset in model training\n",
    "model.fit(\n",
    "   train_dataset,\n",
    "   epochs=50,\n",
    "   validation_data=valid_dataset,\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('unet_pannuke5')\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "threshold = 0.2\n",
    "y_test1 = (y_test > threshold).astype(int)\n",
    "predicted1 = (predicted > threshold).astype(int)\n",
    "predicted1 = np.squeeze(predicted1, axis=-1)\n",
    "# Calculate metrics\n",
    "dice = dice_coefficient(y_test1, predicted1)\n",
    "iou_value = iou(y_test1, predicted1)\n",
    "precision_value = precision(y_test1, predicted1)\n",
    "recall_value = recall(y_test1, predicted1)\n",
    "specificity_value = specificity(y_test1, predicted1)\n",
    "accuracy_value = accuracy(y_test1, predicted1)\n",
    "# Print the results\n",
    "print(f\"Dice Coefficient: {dice:.2f}%\")\n",
    "print(f\"IoU (Jaccard Index): {iou_value:.2f}%\")\n",
    "print(f\"Precision: {precision_value:.2f}%\")\n",
    "print(f\"Recall: {recall_value:.2f}%\")\n",
    "print(f\"Specificity: {specificity_value:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_value:.2f}%\")\n",
    "# print(f\"AJI: {aji:.2f}%\")\n",
    "\n",
    "fig=plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "ax=fig.add_subplot(1,2,1)\n",
    "ax.imshow(y_test[2],cmap=\"gray\")\n",
    "ax=fig.add_subplot(1,2,2)\n",
    "ax.imshow(predicted1[2],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/conv2d_transpose_2/conv2d_transpose' defined at (most recent call last):\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25240\\4274699072.py\", line 202, in <module>\n      model.fit(\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\layers\\convolutional\\conv2d_transpose.py\", line 296, in call\n      outputs = backend.conv2d_transpose(\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\backend.py\", line 6119, in conv2d_transpose\n      x = tf.compat.v1.nn.conv2d_transpose(\nNode: 'model_1/conv2d_transpose_2/conv2d_transpose'\nOOM when allocating tensor with shape[8,64,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/conv2d_transpose_2/conv2d_transpose}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_9900]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 202\u001b[0m\n\u001b[0;32m    198\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39madam, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# Use the Dataset in model training\u001b[39;00m\n\u001b[1;32m--> 202\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m   \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m   \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m    209\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_pannuke5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/conv2d_transpose_2/conv2d_transpose' defined at (most recent call last):\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n      app.start()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n      self.io_loop.start()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n      await result\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25240\\4274699072.py\", line 202, in <module>\n      model.fit(\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 510, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\functional.py\", line 667, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\layers\\convolutional\\conv2d_transpose.py\", line 296, in call\n      outputs = backend.conv2d_transpose(\n    File \"C:\\Users\\HP\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\backend.py\", line 6119, in conv2d_transpose\n      x = tf.compat.v1.nn.conv2d_transpose(\nNode: 'model_1/conv2d_transpose_2/conv2d_transpose'\nOOM when allocating tensor with shape[8,64,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/conv2d_transpose_2/conv2d_transpose}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_9900]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def attention_block_2d(x, g, inter_channel):\n",
    "    # theta_x(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    theta_x = Conv2D(filters=inter_channel, kernel_size=(1, 1), strides=(1, 1),padding='same')(x)\n",
    "\n",
    "    # phi_g(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    phi_g = Conv2D(filters=inter_channel, kernel_size=(1, 1), strides=(1, 1),padding='same')(g)\n",
    "\n",
    "    # f(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    f = Activation('relu')(add([theta_x, phi_g]))\n",
    "\n",
    "    # psi_f(?,g_height,g_width,1)\n",
    "\n",
    "    psi_f = Conv2D(filters=1, kernel_size=(1, 1), strides=(1, 1),padding='same')(f)\n",
    "\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "    # rate(?,x_height,x_width)\n",
    "\n",
    "    # att_x(?,x_height,x_width,x_channel)\n",
    "\n",
    "    att_x = multiply([x, rate])\n",
    "\n",
    "    return att_x\n",
    "\n",
    "def attention_up_and_concate(down_layer, layer):\n",
    "\n",
    "    in_channel = down_layer.get_shape().as_list()[3]\n",
    "\n",
    "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
    "    up = UpSampling2D(size=(2, 2),interpolation = 'nearest')(down_layer)\n",
    "\n",
    "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4)\n",
    "\n",
    "    concate = concatenate([up, layer], axis=3)\n",
    "\n",
    "    return concate\n",
    "def down_block(x, filt):\n",
    "    cn = Conv2D(filters = filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(x)\n",
    "    d1 =  Dropout(0.2)(cn)\n",
    "    cn1 = Conv2D(filters = filt,  kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(d1)\n",
    "    p = MaxPooling2D((2, 2), strides=(2, 2),padding='same')(cn1)\n",
    "    return cn1, p\n",
    "\n",
    "def up_block(x, skip, filt):\n",
    "    concat = attention_up_and_concate(x, skip)\n",
    "    cnn = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(concat)\n",
    "    d2 =  Dropout(0.2)(cnn)\n",
    "    cnn1 = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(d2)\n",
    "    return cnn1\n",
    "\n",
    "def bottleneck(x, filt):\n",
    "    cnt = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(x)\n",
    "    d3 = Dropout(0.2)(cnt)\n",
    "    cnt1 = Conv2D(filters=filt, kernel_size=(3, 3), strides=1, padding='same', activation='relu',\n",
    "               use_bias=True, kernel_initializer='glorot_normal')(d3)\n",
    "    return cnt1\n",
    "\n",
    "def att_UNet():\n",
    "    f = [32, 64, 128, 256, 512, 1024]\n",
    "    #inputs = keras.layers.Input((image_size, image_size, 3))\n",
    "    inputs= Input((256,256,3))\n",
    "\n",
    "    # p0 = inputs\n",
    "    c1, p1 = down_block(inputs, f[0]) #128 -> 64\n",
    "    c2, p2 = down_block(p1, f[1]) #64 -> 32\n",
    "    c3, p3 = down_block(p2, f[2]) #32 -> 16\n",
    "    c4, p4 = down_block(p3, f[3]) #16->8\n",
    "    pd1 = Dropout(0.2)(p4)\n",
    "    bn = bottleneck(pd1, f[4])\n",
    "    pd2 = Dropout(0.2)(bn)\n",
    "    u1 = up_block(pd2, c4, f[3]) #8 -> 16\n",
    "    u2 = up_block(u1, c3, f[2]) #16 -> 32\n",
    "    u3 = up_block(u2, c2, f[1]) #32 -> 64\n",
    "    u4 = up_block(u3, c1, f[0]) #64 -> 128\n",
    "\n",
    "    outputs = Conv2D(filters=1, kernel_size=(1,1), strides=(1,1), padding='same', activation='sigmoid')(u4)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "def CropAndMerge(Input1, Input2, name=\"bridge\"):\n",
    "    \"\"\"\n",
    "    Crop input1 so that it matches input2 and then\n",
    "    return the concatenation of both channels.\n",
    "    \"\"\"\n",
    "    Size1_x = (Input1).shape[1]\n",
    "    Size2_x = (Input2).shape[1]\n",
    "\n",
    "    Size1_y = (Input1).shape[2]\n",
    "    Size2_y = (Input2).shape[2]\n",
    "\n",
    "    diff_x = tf.divide(tf.subtract(Size1_x, Size2_x), 2)\n",
    "    diff_y = tf.divide(tf.subtract(Size1_y, Size2_y), 2)\n",
    "    diff_x = tf.cast(diff_x, tf.int32)\n",
    "    Size2_x = tf.cast(Size2_x, tf.int32)\n",
    "    diff_y = tf.cast(diff_y, tf.int32)\n",
    "    Size2_y = tf.cast(Size2_y, tf.int32)\n",
    "    crop = tf.slice(Input1, [0, diff_x, diff_y, 0], [-1, Size2_x, Size2_y, -1])\n",
    "    concat = tf.concat([crop, Input2], axis=3)\n",
    "\n",
    "    return concat\n",
    "\n",
    "\n",
    "def bn_conv_relu(input, filters):\n",
    "    x = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same', use_bias=True,\n",
    "               kernel_initializer='glorot_normal', bias_initializer=Constant(0.1))(input)\n",
    "    x = BatchNormalization(epsilon=1e-3, beta_initializer=Constant(0.0), gamma_initializer=Constant(1.0), momentum=0.5)(\n",
    "        x)\n",
    "    x = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding='same', use_bias=True,\n",
    "               kernel_initializer='glorot_normal', bias_initializer=Constant(0.1))(x)\n",
    "    x = BatchNormalization(epsilon=1e-3, beta_initializer=Constant(0.0), gamma_initializer=Constant(1.0), momentum=0.5)(\n",
    "        x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def bn_upconv_relu(input, filters, conc):\n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=(2, 2), activation='relu', strides=(2, 2), padding='same',\n",
    "                        kernel_initializer='glorot_normal', bias_initializer=Constant(0.1), use_bias=True)(input)\n",
    "    x = CropAndMerge(Input1=x, Input2=conc, name='bridge')\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def dist(\n",
    "\n",
    "        num_classes=1,\n",
    "        output_activation='sigmoid'):\n",
    "    inputs = Input((256, 256, 3))\n",
    "\n",
    "    filters = [32, 64, 128, 256, 512]\n",
    "\n",
    "    # for l in range(num_layers):\n",
    "    x_conv1 = bn_conv_relu(inputs, filters[0])\n",
    "    x_pool1 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\")(x_conv1)\n",
    "    x_conv2 = bn_conv_relu(x_pool1, filters[1])\n",
    "    x_pool2 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\")(x_conv2)\n",
    "    x_conv3 = bn_conv_relu(x_pool2, filters[2])\n",
    "    x_pool3 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\")(x_conv3)\n",
    "    x_conv4 = bn_conv_relu(x_pool3, filters[3])\n",
    "    x_pool4 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\")(x_conv4)\n",
    "    x_conv5 = bn_conv_relu(x_pool4, filters[4])\n",
    "\n",
    "    # upsampling in the form of convtranspose\n",
    "\n",
    "    x_tconv5 = bn_upconv_relu(x_conv5, filters[3], x_conv4)\n",
    "    u_conv4 = bn_conv_relu(x_tconv5, filters[3])\n",
    "    x_tconv4 = bn_upconv_relu(u_conv4, filters[2], x_conv3)\n",
    "    u_conv3 = bn_conv_relu(x_tconv4, filters[2])\n",
    "    x_tconv3 = bn_upconv_relu(u_conv3, filters[1], x_conv2)\n",
    "    u_conv2 = bn_conv_relu(x_tconv3, filters[1])\n",
    "    x_tconv2 = bn_upconv_relu(u_conv2, filters[0], x_conv1)\n",
    "    u_conv1 = bn_conv_relu(x_tconv2, filters[0])\n",
    "\n",
    "    outputs = Conv2D(num_classes, kernel_size=(1, 1), strides=(1, 1), activation=output_activation, padding='same')(\n",
    "        u_conv1)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "dice_values = []\n",
    "iou_values = []\n",
    "precision_values = []\n",
    "recall_values = []\n",
    "specificity_values = []\n",
    "accuracy_values = []\n",
    "fpr=[]\n",
    "fnr=[]\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "decay_rate = 0.99\n",
    "decay_steps = 10  # Decay the learning rate after every 10 epochs\n",
    "\n",
    "# Define the learning rate schedule\n",
    "def learning_rate_scheduler(epoch):\n",
    "    return initial_learning_rate * decay_rate ** (epoch // decay_steps)\n",
    "\n",
    "# Create an Adam optimizer with the specified initial learning rate\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "\n",
    "# model.compile(optimizer=optimizers.Adam(lr=0.001), loss=dice_loss, metrics=['accuracy'], run_eagerly=True)\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(8)\n",
    "# valid_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(8)\n",
    "# model.summary()\n",
    "\n",
    "model = dist()\n",
    "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Use the Dataset in model training\n",
    "model.fit(\n",
    "   train_dataset,\n",
    "   epochs=50,\n",
    "   validation_data=valid_dataset,\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('attention_pannuke5')\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "threshold = 0.2\n",
    "y_test1 = (y_test > threshold).astype(int)\n",
    "predicted1 = (predicted > threshold).astype(int)\n",
    "predicted1 = np.squeeze(predicted1, axis=-1)\n",
    "# Calculate metrics\n",
    "dice = dice_coefficient(y_test1, predicted1)\n",
    "iou_value = iou(y_test1, predicted1)\n",
    "precision_value = precision(y_test1, predicted1)\n",
    "recall_value = recall(y_test1, predicted1)\n",
    "specificity_value = specificity(y_test1, predicted1)\n",
    "accuracy_value = accuracy(y_test1, predicted1)\n",
    "# Print the results\n",
    "print(f\"Dice Coefficient: {dice:.2f}%\")\n",
    "print(f\"IoU (Jaccard Index): {iou_value:.2f}%\")\n",
    "print(f\"Precision: {precision_value:.2f}%\")\n",
    "print(f\"Recall: {recall_value:.2f}%\")\n",
    "print(f\"Specificity: {specificity_value:.2f}%\")\n",
    "print(f\"Accuracy: {accuracy_value:.2f}%\")\n",
    "# print(f\"AJI: {aji:.2f}%\")\n",
    "\n",
    "fig=plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "ax=fig.add_subplot(1,2,1)\n",
    "ax.imshow(y_test[2],cmap=\"gray\")\n",
    "ax=fig.add_subplot(1,2,2)\n",
    "ax.imshow(predicted1[2],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.keras.utils.custom_object_scope({'dice_jaccard_loss': dice_jaccard_loss}):\n",
    "#     model = load_model('proposed_pannuke')\n",
    "\n",
    "# # predicted = model.predict(X_test)\n",
    "# threshold = 0.5\n",
    "# y_test1 = (y_test > threshold).astype(int)\n",
    "# predicted1 = (predicted > threshold).astype(int)\n",
    "# predicted1 = np.squeeze(predicted1, axis=-1)\n",
    "# # Calculate metrics\n",
    "# dice = dice_coefficient(y_test1, predicted1)\n",
    "# iou_value = iou(y_test1, predicted1)\n",
    "# precision_value = precision(y_test1, predicted1)\n",
    "# recall_value = recall(y_test1, predicted1)\n",
    "# specificity_value = specificity(y_test1, predicted1)\n",
    "# accuracy_value = accuracy(y_test1, predicted1)\n",
    "# # Print the results\n",
    "# print(f\"Dice Coefficient: {dice:.2f}%\")\n",
    "# print(f\"IoU (Jaccard Index): {iou_value:.2f}%\")\n",
    "# print(f\"Precision: {precision_value:.2f}%\")\n",
    "# print(f\"Recall: {recall_value:.2f}%\")\n",
    "# print(f\"Specificity: {specificity_value:.2f}%\")\n",
    "# print(f\"Accuracy: {accuracy_value:.2f}%\")\n",
    "# # print(f\"AJI: {aji:.2f}%\")\n",
    "\n",
    "# fig=plt.figure()\n",
    "\n",
    "# fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "# ax=fig.add_subplot(1,2,1)\n",
    "# ax.imshow(y_test[2],cmap=\"gray\")\n",
    "\n",
    "# ax=fig.add_subplot(1,2,2)\n",
    "# ax.imshow(predicted1[2],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.keras.utils.custom_object_scope({'loss': loss}):\n",
    "#     model = load_model('dan_pannuke')\n",
    "# predicted = model.predict(X_test)\n",
    "# threshold = 0.8\n",
    "# y_test1 = (y_test > threshold).astype(int)\n",
    "# predicted1 = (predicted > threshold).astype(int)\n",
    "# predicted1 = np.squeeze(predicted1, axis=-1)\n",
    "# # Calculate metrics\n",
    "# dice = dice_coefficient(y_test1, predicted1)\n",
    "# iou_value = iou(y_test1, predicted1)\n",
    "# precision_value = precision(y_test1, predicted1)\n",
    "# recall_value = recall(y_test1, predicted1)\n",
    "# specificity_value = specificity(y_test1, predicted1)\n",
    "# accuracy_value = accuracy(y_test1, predicted1)\n",
    "# # Print the results\n",
    "# print(f\"Dice Coefficient: {dice:.2f}%\")\n",
    "# print(f\"IoU (Jaccard Index): {iou_value:.2f}%\")\n",
    "# print(f\"Precision: {precision_value:.2f}%\")\n",
    "# print(f\"Recall: {recall_value:.2f}%\")\n",
    "# print(f\"Specificity: {specificity_value:.2f}%\")\n",
    "# print(f\"Accuracy: {accuracy_value:.2f}%\")\n",
    "# # print(f\"AJI: {aji:.2f}%\")\n",
    "\n",
    "# fig=plt.figure()\n",
    "\n",
    "# fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "# ax=fig.add_subplot(1,2,1)\n",
    "# ax.imshow(y_test[2],cmap=\"gray\")\n",
    "\n",
    "# ax=fig.add_subplot(1,2,2)\n",
    "# ax.imshow(predicted1[2],cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "12-27UbOrnK_uvABPsEN1uxw_3NUagapP",
     "timestamp": 1719912613132
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
